{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for stream sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE_BYTE = 512 * 1024 * 1024\n",
    "EDGE_FILE = \"/mnt/nvme2/data/yahoo/edges.bin\"\n",
    "DEGREE_FILE = \"/mnt/nvme2/data/yahoo/degree.bin\"\n",
    "\n",
    "# files to write\n",
    "STREAMING_EDGE_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/streaming_edges.bin\"\n",
    "CHUNK_INFO_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/chunks.txt\"\n",
    "TRAIN_NODE_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/train.bin\"\n",
    "RANDOM_READ_EDGE_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/random_read_edges.bin\"\n",
    "OFFSET_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/offset.bin\"\n",
    "\n",
    "SEQUENTIAL_READ_EDGE_FILE = \"/mnt/nvme2/data/yahoo/preprocessed/sequential_read.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "# also need jupyter and ipywidgets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origianl file must be preprocess by yahoo.cpp before using this jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from taw text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_RAW = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_all_edges(filepath):\n",
    "    print(\"Reading edges from file\")\n",
    "    return np.fromfile(filepath, dtype=np.uint32)\n",
    "\n",
    "def read_in_degrees(filepath):\n",
    "    print(\"Reading degrees from file\")\n",
    "    return np.fromfile(filepath, dtype=np.uint32)\n",
    "\n",
    "def compute_offsets(degrees):\n",
    "    offsets = np.zeros(len(degrees), dtype=np.uint64)\n",
    "    offsets[0] = 0\n",
    "    pbar = tqdm(total=len(degrees), desc=\"Compute offsets\")\n",
    "    for i in range(len(degrees) - 1):\n",
    "        offsets[i+1] = offsets[i] + degrees[i]\n",
    "        if i % 1000000 == 0:\n",
    "            pbar.update(1000000)\n",
    "    pbar.close()\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading degrees from file\n",
      "Reading edges from file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c69380798d64a51b8fcdbf12babb265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute offsets:   0%|          | 0/1413511394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if LOAD_FROM_RAW:\n",
    "    degrees = read_in_degrees(DEGREE_FILE)\n",
    "    edges = read_in_all_edges(EDGE_FILE)\n",
    "    offsets = compute_offsets(degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create padded file for treaming sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_STREAMING_SAMPLER_FILE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where to split the edges into chunks\n",
    "def analysis_chunks(degrees, chunk_size=CHUNK_SIZE_BYTE):\n",
    "    max_ints = chunk_size // 4\n",
    "\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    current_chunk_size = 3 \n",
    "    pbar = tqdm(total=len(degrees))\n",
    "    for i in range(len(degrees)):\n",
    "        if i % 1000000 == 0:\n",
    "            pbar.update(1000000)\n",
    "        if current_chunk_size + degrees[i] + 1 > max_ints:\n",
    "            chunks.append((start, i-1))\n",
    "            start = i\n",
    "            current_chunk_size = 3\n",
    "        current_chunk_size += degrees[i] + 1\n",
    "    chunks.append((start, len(degrees)-1))\n",
    "    pbar.close()\n",
    "    return chunks\n",
    "\n",
    "def print_chunk_details(chunks, degrees):\n",
    "    print(\"Chunk Details\")\n",
    "    print(\"=\"*12*5)\n",
    "    print(f\"{'start':>12}{'end':>12}{'n_nodes':>12}{'size(bytes)':>12}{'fill up':>12}\")\n",
    "    for chunk in chunks:\n",
    "        start = chunk[0]\n",
    "        end = chunk[1]\n",
    "        n_nodes = sum(degrees[start:end+1])\n",
    "        size = (1 + 1 + (end - start + 2) + n_nodes ) * 4\n",
    "        print(f\"{start:12d}{end:12d}{n_nodes:12d}{size:12d}{size/CHUNK_SIZE_BYTE*100:9.2f}%\")\n",
    "\n",
    "    print(\"len(chunks)\", len(chunks))\n",
    "    print(\"chunks\", chunks)\n",
    "\n",
    "def create_streaming_edge_file(filepath, chunks, degrees, edges):\n",
    "    pbar = tqdm(total=len(chunks), desc=\"Creating padded file\")\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        edges_cnt = 0\n",
    "        for t, chunk in enumerate(chunks):\n",
    "            # write buffer\n",
    "            byte_data_list = []\n",
    "            # total number of nodes, little endian, unsigned int\n",
    "            total_nodes = chunk[1] - chunk[0] + 1\n",
    "            byte_data_list.append(struct.pack(\"<I\", total_nodes))\n",
    "            # first node id, little endian, unsigned int\n",
    "            byte_data_list.append(struct.pack(\"<I\", chunk[0]))\n",
    "            # offsets, little endian, unsigned int\n",
    "            cnt = total_nodes + 2 + 1\n",
    "            byte_data_list.append(struct.pack(\"<I\", cnt))\n",
    "            for i in range(chunk[0], chunk[1]+1):\n",
    "                cnt += degrees[i]\n",
    "                byte_data_list.append(struct.pack(\"<I\", cnt))\n",
    "            # edges, little endian, unsigned int\n",
    "            for i in range(chunk[0], chunk[1]+1):\n",
    "                for j in range(edges_cnt, edges_cnt + degrees[i]):\n",
    "                    byte_data_list.append(struct.pack(\"<I\", edges[j]))\n",
    "                edges_cnt += degrees[i]\n",
    "            # padding zeros, unsigned int\n",
    "            # For the last chunk, padding to make the chunk size a multiple of 512\n",
    "            byte_data = b''.join(byte_data_list)\n",
    "            file.write(byte_data)\n",
    "            if t != len(chunks) - 1:\n",
    "                bytes_to_add = CHUNK_SIZE_BYTE - len(byte_data)\n",
    "            else:\n",
    "                bytes_to_add = 512 - len(byte_data) % 512\n",
    "            file.write(b'\\x00' * bytes_to_add)\n",
    "            # print(t, len(byte_data) + bytes_to_add)\n",
    "            pbar.update(1)\n",
    "            \n",
    "    pbar.close()\n",
    "\n",
    "def create_chunk_file(filepath, chunks):\n",
    "    with open(filepath, \"w\") as fh:\n",
    "        # fh.write(f\"{len(chunks)}\\n\")\n",
    "        for chunk in chunks:\n",
    "            # fh.write(f\"{chunk[0]} {chunk[1]}\\n\")\n",
    "            fh.write(f\"{chunk[1]}\\n\")\n",
    "        \n",
    "def create_train_nodes(filepath ):\n",
    "    with open(filepath, \"wb\") as fh:\n",
    "        byte_data_list = [struct.pack(\"<I\", x) for x in range(1400000)]\n",
    "        byte_data = b''.join(byte_data_list)\n",
    "        fh.write(byte_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_read_edge_file(filepath, chunks, degrees, edges):\n",
    "    pbar = tqdm(total=len(chunks), desc=\"Creating padded file\")\n",
    "    with open(filepath, \"wb\") as file:\n",
    "        edges_cnt = 0\n",
    "        for t, chunk in enumerate(chunks):\n",
    "            # write buffer\n",
    "            byte_data_list = []\n",
    "            # total number of nodes, little endian, unsigned int\n",
    "            total_nodes = chunk[1] - chunk[0] + 1\n",
    "            byte_data_list.append(struct.pack(\"<I\", total_nodes))\n",
    "            # first node id, little endian, unsigned int\n",
    "            byte_data_list.append(struct.pack(\"<I\", chunk[0]))\n",
    "            # offsets, little endian, unsigned int\n",
    "            for i in range(chunk[0], chunk[1]+1):\n",
    "                byte_data_list.append(struct.pack(\"<I\", degrees[i]))\n",
    "                for j in range(edges_cnt, edges_cnt + degrees[i]):\n",
    "                    byte_data_list.append(struct.pack(\"<I\", edges[j]))\n",
    "                edges_cnt += degrees[i]\n",
    "            \n",
    "            byte_data = b''.join(byte_data_list)\n",
    "            file.write(byte_data)\n",
    "            if t != len(chunks) - 1:\n",
    "                bytes_to_add = CHUNK_SIZE_BYTE - len(byte_data)\n",
    "            else:\n",
    "                bytes_to_add = 512 - len(byte_data) % 512\n",
    "            file.write(b'\\x00' * bytes_to_add)\n",
    "            pbar.update(1)\n",
    "            print(t, len(byte_data), bytes_to_add, len(byte_data) + bytes_to_add)\n",
    "            \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_SEQUENTIAL_READ_SAMPLER_FILE = True\n",
    "if CREATE_SEQUENTIAL_READ_SAMPLER_FILE:\n",
    "    chunks = analysis_chunks(degrees)\n",
    "    print_chunk_details(chunks, degrees)\n",
    "    create_seq_read_edge_file(SEQUENTIAL_READ_EDGE_FILE, chunks, degrees, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fdcd4312f846f3bf820ad1285ceb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating padded file:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 536870492 420 536870912\n",
      "1 536870248 664 536870912\n",
      "2 536865952 4960 536870912\n",
      "3 536869676 1236 536870912\n",
      "4 536870904 8 536870912\n",
      "5 536870892 20 536870912\n",
      "6 536870840 72 536870912\n",
      "7 536870788 124 536870912\n",
      "8 536870856 56 536870912\n",
      "9 536870844 68 536870912\n",
      "10 536870624 288 536870912\n",
      "11 536870884 28 536870912\n",
      "12 536870896 16 536870912\n",
      "13 536870660 252 536870912\n",
      "14 536870720 192 536870912\n",
      "15 536870904 8 536870912\n",
      "16 536870744 168 536870912\n",
      "17 536870876 36 536870912\n",
      "18 536870840 72 536870912\n",
      "19 536870860 52 536870912\n",
      "20 536870892 20 536870912\n",
      "21 536870884 28 536870912\n",
      "22 536870388 524 536870912\n",
      "23 536870836 76 536870912\n",
      "24 536870888 24 536870912\n",
      "25 536870712 200 536870912\n",
      "26 536870900 12 536870912\n",
      "27 536870868 44 536870912\n",
      "28 536870816 96 536870912\n",
      "29 536870792 120 536870912\n",
      "30 536870724 188 536870912\n",
      "31 536870792 120 536870912\n",
      "32 536870776 136 536870912\n",
      "33 536870712 200 536870912\n",
      "34 536870848 64 536870912\n",
      "35 536870908 4 536870912\n",
      "36 536870908 4 536870912\n",
      "37 536870908 4 536870912\n",
      "38 536870880 32 536870912\n",
      "39 536870908 4 536870912\n",
      "40 536870908 4 536870912\n",
      "41 536870900 12 536870912\n",
      "42 536870880 32 536870912\n",
      "43 536870904 8 536870912\n",
      "44 536870908 4 536870912\n",
      "45 536870860 52 536870912\n",
      "46 536870908 4 536870912\n",
      "47 536870892 20 536870912\n",
      "48 536870872 40 536870912\n",
      "49 536870876 36 536870912\n",
      "50 536870900 12 536870912\n",
      "51 536870904 8 536870912\n",
      "52 536870848 64 536870912\n",
      "53 536870908 4 536870912\n",
      "54 536870904 8 536870912\n",
      "55 536870896 16 536870912\n",
      "56 536870908 4 536870912\n",
      "57 536870904 8 536870912\n",
      "58 536870908 4 536870912\n",
      "59 525076344 136 525076480\n"
     ]
    }
   ],
   "source": [
    "create_seq_read_edge_file(SEQUENTIAL_READ_EDGE_FILE, chunks, degrees, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e694a5ab2caf4daa9194f2e7160869d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413511394 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Details\n",
      "============================================================\n",
      "       start         end     n_nodes size(bytes)     fill up\n",
      "           0      617287   133600333   536870496   100.00%\n",
      "      617288     1312180   133522667   536870252   100.00%\n",
      "     1312181     1965516   133563150   536865956   100.00%\n",
      "     1965517     2615657   133567276   536869680   100.00%\n",
      "     2615658     3947779   132885602   536870908   100.00%\n",
      "     3947780     8192152   129973348   536870896   100.00%\n",
      "     8192153    12083098   130326762   536870844   100.00%\n",
      "    12083099    16228722   130072071   536870792   100.00%\n",
      "    16228723    20284312   130162122   536870860   100.00%\n",
      "    20284313    24484493   130017528   536870848   100.00%\n",
      "    24484494    28386289   130315858   536870628   100.00%\n",
      "    28386290    32006505   130597503   536870888   100.00%\n",
      "    32006506    36186961   130037266   536870900   100.00%\n",
      "    36186962    40202824   130201800   536870664   100.00%\n",
      "    40202825    44258051   130162451   536870724   100.00%\n",
      "    44258052    48138725   130337050   536870908   100.00%\n",
      "    48138726    51712098   130644311   536870748   100.00%\n",
      "    51712099    55951026   129978789   536870880   100.00%\n",
      "    55951027    60190959   129977775   536870844   100.00%\n",
      "    60190960    64315665   130093007   536870864   100.00%\n",
      "    64315666    68332470   130200916   536870896   100.00%\n",
      "    68332471    72135894   130414295   536870888   100.00%\n",
      "    72135895    76299303   130054186   536870392   100.00%\n",
      "    76299304    80660997   129856013   536870840   100.00%\n",
      "    80660998    84342284   130536433   536870892   100.00%\n",
      "    84342285    88199413   130360547   536870716   100.00%\n",
      "    88199414    92531627   129885509   536870904   100.00%\n",
      "    92531628    96933377   129815965   536870872   100.00%\n",
      "    96933378   100908417   130242662   536870820   100.00%\n",
      "   100908418   104844865   130281248   536870796   100.00%\n",
      "   104844866   108739065   130323479   536870728   100.00%\n",
      "   108739066   112970045   129986716   536870796   100.00%\n",
      "   112970046   117064365   130123372   536870780   100.00%\n",
      "   117064366   120973355   130308686   536870716   100.00%\n",
      "   120973356   125081742   130109323   536870852   100.00%\n",
      "   125081743   143733786   115565681   536870912   100.00%\n",
      "   143733787   192759528    85191983   536870912   100.00%\n",
      "   192759529   244277071    82700182   536870912   100.00%\n",
      "   244277072   292403896    86090893   536870884   100.00%\n",
      "   292403897   338554815    88066806   536870912   100.00%\n",
      "   338554816   385076406    87696134   536870912   100.00%\n",
      "   385076407   436845908    82448221   536870904   100.00%\n",
      "   436845909   491878825    79184801   536870884   100.00%\n",
      "   491878826   546354138    79742411   536870908   100.00%\n",
      "   546354139   600173940    80397923   536870912   100.00%\n",
      "   600173941   655563228    78828425   536870864   100.00%\n",
      "   655563229   708878441    80902512   536870912   100.00%\n",
      "   708878442   760906094    82190068   536870896   100.00%\n",
      "   760906095   814806709    80317101   536870876   100.00%\n",
      "   814806710   870147284    78877142   536870880   100.00%\n",
      "   870147285   929896550    74468457   536870904   100.00%\n",
      "   929896551   985022660    79091614   536870908   100.00%\n",
      "   985022661  1039052424    80187946   536870852   100.00%\n",
      "  1039052425  1095958621    77311528   536870912   100.00%\n",
      "  1095958622  1148304631    81871714   536870908   100.00%\n",
      "  1148304632  1203012054    79510299   536870900   100.00%\n",
      "  1203012055  1256883601    80346178   536870912   100.00%\n",
      "  1256883602  1309049644    82051681   536870908   100.00%\n",
      "  1309049645  1360102796    83164573   536870912   100.00%\n",
      "  1360102797  1413511393    77860487   525076348    97.80%\n",
      "len(chunks) 60\n",
      "chunks [(0, 617287), (617288, 1312180), (1312181, 1965516), (1965517, 2615657), (2615658, 3947779), (3947780, 8192152), (8192153, 12083098), (12083099, 16228722), (16228723, 20284312), (20284313, 24484493), (24484494, 28386289), (28386290, 32006505), (32006506, 36186961), (36186962, 40202824), (40202825, 44258051), (44258052, 48138725), (48138726, 51712098), (51712099, 55951026), (55951027, 60190959), (60190960, 64315665), (64315666, 68332470), (68332471, 72135894), (72135895, 76299303), (76299304, 80660997), (80660998, 84342284), (84342285, 88199413), (88199414, 92531627), (92531628, 96933377), (96933378, 100908417), (100908418, 104844865), (104844866, 108739065), (108739066, 112970045), (112970046, 117064365), (117064366, 120973355), (120973356, 125081742), (125081743, 143733786), (143733787, 192759528), (192759529, 244277071), (244277072, 292403896), (292403897, 338554815), (338554816, 385076406), (385076407, 436845908), (436845909, 491878825), (491878826, 546354138), (546354139, 600173940), (600173941, 655563228), (655563229, 708878441), (708878442, 760906094), (760906095, 814806709), (814806710, 870147284), (870147285, 929896550), (929896551, 985022660), (985022661, 1039052424), (1039052425, 1095958621), (1095958622, 1148304631), (1148304632, 1203012054), (1203012055, 1256883601), (1256883602, 1309049644), (1309049645, 1360102796), (1360102797, 1413511393)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3330c3884ff249ccb320294937a7637a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating padded file:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CREATE_STREAMING_SAMPLER_FILE:\n",
    "    chunks = analysis_chunks(degrees)\n",
    "    print_chunk_details(chunks, degrees)\n",
    "    create_streaming_edge_file(STREAMING_EDGE_FILE, chunks, degrees, edges)\n",
    "    create_chunk_file(CHUNK_INFO_FILE, chunks)\n",
    "    create_train_nodes(TRAIN_NODE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for random read sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_RANDOM_READ_SAMPLER_FILE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_read_edge_file(edges, output_file_path):\n",
    "    assert edges.dtype.byteorder != '>', \"Numpy array shoule not be big endian\"\n",
    "    edges.tofile(output_file_path)\n",
    "    padding_needed = 512 - (len(edges) * 4) % 512\n",
    "\n",
    "    if padding_needed > 0:\n",
    "         with open(output_file_path, 'ab') as file:\n",
    "            file.write(b'\\x00' * padding_needed)\n",
    "\n",
    "    print(f\"File {output_file_path} has been padded with {padding_needed} bytes.\")\n",
    "\n",
    "\n",
    "def create_offsets_file(offsets, output_file_path):\n",
    "    offsets.tofile(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /mnt/nvme2/data/yahoo/preprocessed/random_read_edges.bin has been padded with 212 bytes.\n"
     ]
    }
   ],
   "source": [
    "if CREATE_RANDOM_READ_SAMPLER_FILE:\n",
    "    create_random_read_edge_file(edges, RANDOM_READ_EDGE_FILE)\n",
    "    create_offsets_file(offsets, OFFSET_FILE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_edges = np.fromfile(STREAMING_EDGE_FILE, dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa0cb0a97224d1cb489ffddeb6992bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True 0 617287\n",
      "1 True 617288 694892\n",
      "2 True 1312181 653335\n",
      "3 True 1965517 650140\n",
      "4 True 2615658 1332121\n",
      "5 True 3947780 4244372\n",
      "6 True 8192153 3890945\n",
      "7 True 12083099 4145623\n",
      "8 True 16228723 4055589\n",
      "9 True 20284313 4200180\n",
      "10 True 24484494 3901795\n",
      "11 True 28386290 3620215\n",
      "12 True 32006506 4180455\n",
      "13 True 36186962 4015862\n",
      "14 True 40202825 4055226\n",
      "15 True 44258052 3880673\n",
      "16 True 48138726 3573372\n",
      "17 True 51712099 4238927\n",
      "18 True 55951027 4239932\n",
      "19 True 60190960 4124705\n",
      "20 True 64315666 4016804\n",
      "21 True 68332471 3803423\n",
      "22 True 72135895 4163408\n",
      "23 True 76299304 4361693\n",
      "24 True 80660998 3681286\n",
      "25 True 84342285 3857128\n",
      "26 True 88199414 4332213\n",
      "27 True 92531628 4401749\n",
      "28 True 96933378 3975039\n",
      "29 True 100908418 3936447\n",
      "30 True 104844866 3894199\n",
      "31 True 108739066 4230979\n",
      "32 True 112970046 4094319\n",
      "33 True 117064366 3908989\n",
      "34 True 120973356 4108386\n",
      "35 True 125081743 18652043\n",
      "36 True 143733787 49025741\n",
      "37 True 192759529 51517542\n",
      "38 True 244277072 48126824\n",
      "39 True 292403897 46150918\n",
      "40 True 338554816 46521590\n",
      "41 True 385076407 51769501\n",
      "42 True 436845909 55032916\n",
      "43 True 491878826 54475312\n",
      "44 True 546354139 53819801\n",
      "45 True 600173941 55389287\n",
      "46 True 655563229 53315212\n",
      "47 True 708878442 52027652\n",
      "48 True 760906095 53900614\n",
      "49 True 814806710 55340574\n",
      "50 True 870147285 59749265\n",
      "51 True 929896551 55126109\n",
      "52 True 985022661 54029763\n",
      "53 True 1039052425 56906196\n",
      "54 True 1095958622 52346009\n",
      "55 True 1148304632 54707422\n",
      "56 True 1203012055 53871546\n",
      "57 True 1256883602 52166042\n",
      "58 True 1309049645 51053151\n",
      "59 True 1360102797 53408596\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=60)\n",
    "for t in range(60):\n",
    "    start_pos = t * CHUNK_SIZE_BYTE // 4\n",
    "    cur_total = streaming_edges[start_pos + 0]\n",
    "    start_node = streaming_edges[start_pos + 1]\n",
    "    cur_offsets = streaming_edges[start_pos + 2: start_pos + 2 + cur_total + 1]\n",
    "    is_assending = np.all(cur_offsets[1:] >= cur_offsets[:-1])\n",
    "    print(t, is_assending, start_node, cur_total)\n",
    "    # assert is_assending, f\"Chunk {t} is not assending\"\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_edges = np.fromfile(SEQUENTIAL_READ_EDGE_FILE, dtype=np.uint32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([617288,      0, 617291, 617291, 617291, 617291, 617291, 617585,\n",
       "       617585, 617585, 617585, 617585, 617602, 617606, 617626, 617626,\n",
       "       617626, 617851, 618075, 618075, 618303, 618527, 618752, 618977,\n",
       "       618977, 618993, 619218, 619218, 619448, 619679, 619679, 619911,\n",
       "       620145, 620297, 620297, 620331, 620523, 620747, 620747, 620757],\n",
       "      dtype=uint32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_edges[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0, 294,   0,   0,   0,   0,  17], dtype=uint32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees[:10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
